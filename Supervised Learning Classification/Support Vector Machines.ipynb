{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a274e2a9",
   "metadata": {},
   "source": [
    "## Soft margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d196104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C values to GridSearch over\n",
    "# pgrid = {\"C\": np.linspace(0.0001, 2, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc235866",
   "metadata": {},
   "source": [
    "#### Parameter: `C`\n",
    "`C` controls how much we regularize the boundary that is fit between classes.\n",
    "- **If `C` is small**: We regularize substantially, leading to a less perfect classification of our training data.\n",
    "- **If `C` is large**: We do not regularize much, leading to a more perfect classification of our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b31cf",
   "metadata": {},
   "source": [
    "As we increase `C`, what happens to our bias-variance tradeoff?\n",
    "\n",
    "- If C is small: We regularize substantially, leading to a less perfect classification of our training data. --> Bias increases, variance decreases.\n",
    "- If C is large: We do not regularize much, leading to a more perfect classification of our training data. --> Bias decreases, variance increases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f626c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # (THREAD) Instantiate and fit a gridsearch model for this SVC!\n",
    "# svc = LinearSVC(max_iter=20000)\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# gcv = GridSearchCV(svc, pgrid, cv=cv)\n",
    "# gcv.fit(X_sc, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca440138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What is the best cross-validated score?\n",
    "# gcv.best_score_\n",
    "\n",
    "# # What is the best model?\n",
    "# gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "270feaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save cv results as a DataFrame\n",
    "# df = pd.DataFrame(gcv.cv_results_)\n",
    "\n",
    "# # Visualize how different values of C affect accuracy\n",
    "# plt.plot(\"param_C\", \"mean_test_score\", data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824d695e",
   "metadata": {},
   "source": [
    "## Kernel SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af41bea",
   "metadata": {},
   "source": [
    "### Hyperparameters of SVMs\n",
    "SVMs will have two main hyperparameters: `C` and `kernel`.\n",
    "\n",
    "#### Parameter: `C`\n",
    "`C` controls how much we regularize the boundary that is fit between classes.\n",
    "- **If `C` is small**: We regularize substantially, leading to a less perfect classification of our training data.\n",
    "- **If `C` is large**: We do not regularize much, leading to a more perfect classification of our training data.\n",
    "\n",
    "#### Parameter: `kernel`\n",
    "There are several options:\n",
    "* `linear`, `rbf`, `polynomial`, `sigmoid`, or something custom\n",
    "\n",
    "**Which do we use?**\n",
    "- **Quick answer**: As long as it's not the linear kernel, it actually matters surprisingly little!\n",
    "- **Lazy answer**: Use the RBF kernel, as it's usually best (or no different from other options).\n",
    "- **Better answer**: It's a model parameter that you're free to gridsearch over!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8fac3e",
   "metadata": {},
   "source": [
    "## Loading with MNIST Digits Dataset (Kernel SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab5b5412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Load digits.\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Check out data.\n",
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f279822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# How many observations do we have?\n",
    "# NOTE: Data is in a NumPy array!\n",
    "print(type(digits.data))\n",
    "print(digits.data.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4410387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate heatmap.\n",
    "plt.imshow(\n",
    "    digits.images[42],\n",
    "    cmap=plt.cm.gray_r,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "081089f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the actual class?\n",
    "digits.target[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f104fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y.\n",
    "X, y = digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcccd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.33,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b417bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate support vector machine.\n",
    "svc = SVC(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb63f045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit support vector machine to training data.\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "601572d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions.\n",
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99fb282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865319865319865"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure performance based on accuracy.\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b91f74",
   "metadata": {},
   "source": [
    "- Accuracy is likely the best metric to use here. Improperly classifying a number is equally bad, no matter what number you incorrectly predict. For example, misclassifying a `4` as a `3` or `5` or `9` is equally bad.\n",
    "- Many of our other classification metrics (like sensitivity and specificity) don't easily generalize to classification with more than two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c732c",
   "metadata": {},
   "source": [
    "SVMs can be used for both classifications and regressions (specify c and kernel).<br>\n",
    "Regression more complicated, but use SVR instead of SVC, then fit and predict.\n",
    "\n",
    "# Pros and Cons of SVMs\n",
    "\n",
    "#### Pros\n",
    "- Exceptional perfomance (historically widely used)\n",
    "- Effective in high-dimensional data\n",
    "- Can work with non-linear boundaries\n",
    "- Fast to compute with most datasets (kernel trick)\n",
    "\n",
    "#### Cons\n",
    "- Black box method\n",
    "- Can be slow on large (tall) datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45457df9",
   "metadata": {},
   "source": [
    "# Concluding Remarks and Fun Facts\n",
    "* SVMs are fantastic models if all you care about is predictive ability.\n",
    "* They are complete and total black boxes, sorry.\n",
    "* You must scale your data.\n",
    "* By the way, doing a kernel SVM with polynomial kernel degree = 2 has been shown to work really well for NLP data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6dec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
